---
title: "Causal Inference Fundamentals"
output:
  html_document:
    theme: cerulean
    highlight: kate
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{=html}
<style>
body {
  font-size: 17px;
  line-height: 1.6;
}
</style>
```

```{r setup, include=FALSE}
library(kernlab)
library(showtext)
library(kableExtra)
library(dplyr)
library(tidyverse)
library(scales)
```

## Causal Inference Fundamentals

In this module, we explore what it means to make a causal claim in the social sciences—and how we can go about evaluating whether one thing truly causes another. We’ll begin by distinguishing causality from correlation and move on to different types of causal definitions, the core assumptions required for estimating causal effects, and finally, best practices for building your own causal theories.

## Part 1: What is Causality?

Causality is about understanding how and why one thing influences another. Rather than simply observing patterns in the data, causal inference asks: What would have happened if things were different?

**Correlation is Not Causation**

It’s important not to confuse correlation with causation. Just because two things tend to happen at the same time doesn’t mean that one causes the other. To really understand causality, we have to dig deeper and ask: Is one thing actually producing a change in the other, or are they just happening side by side because of something else?

```{r, echo=FALSE, fig.align='center', out.width='80%'}
knitr::include_graphics("/Users/jieun/Documents/MAIS_POLI706/figures/icecream.jpg")
```

Let’s take a simple example. Imagine we notice that when ice cream sales go up, the number of sunburn cases also increases. At first glance, this might seem like eating more ice cream somehow causes people to get sunburned. But of course, that doesn’t make sense!

What’s really going on is that both of these things—buying ice cream and getting sunburned—are influenced by a third factor: hot, sunny weather. When the sun is out and temperatures are high, people flock outdoors. They’re more likely to enjoy cold treats like ice cream, and they’re also more likely to spend time in the sun, which increases their chances of getting sunburned. So while there’s a correlation between ice cream sales and sunburns, one doesn’t cause the other.

This is why, when we study causal relationships—especially in political science, economics, or health—we need to go beyond surface-level patterns. We must ask whether there's a plausible mechanism connecting the variables, and whether other explanations might be behind the patterns we see.

In short: correlation can be a useful clue, but it’s not the whole story. To make strong causal claims, we need to do a bit more detective work.

Causal inference helps us rule out spurious relationships and focus on the variables that truly affect our outcome of interest.

**Key Terms**

Dependent Variable (Outcome Variable): This is the main variable you're trying to explain. It represents the result or consequence of other factors. For instance, if you're studying civil conflict, your outcome might be whether or not a country experienced a civil war in a given year.

Explanatory Variables: These are the factors you think might explain or influence the dependent variable. Among these:

- The key causal variable (or treatment) is the main factor you hypothesize has a causal effect.

- Control variables are other variables that might influence the outcome and need to be accounted for to isolate the effect of the key causal variable.

Understanding what causality means, and how it's different from mere association, is the first step toward asking better research questions and designing better studies.

### Descriptive vs. Causal Inference

#### Descriptive Inference

**Descriptive inference** is about learning something that we have not directly observed, based on what we have observed. It goes beyond simply summarizing patterns in the data—it uses those patterns to make informed claims about unknown or unobserved facts.

In Module 2, we practiced descriptive inference by studying the relationship between civil war and the capacity of Election Management Bodies (EMBs). While we visualized and compared EMB capacity scores between countries with and without civil war, we inferred that EMB capacity is correlated with civil war onset. From this observation, we could say:

*“Countries with civil wars tend to have lower EMB capacity scores than those without civil wars.”*

We didn’t just stop at describing the scores in our dataset — we used the patterns in that sample to say something meaningful about the broader population of countries. That’s what makes it descriptive inference.

However, even with statistically significant results, our inference remained descriptive—not causal. We learned that there is an association between civil war and EMB capacity, but we haven’t answered the why. Is civil war causing weaker institutions? Are weak institutions making civil war more likely? Or are both driven by a third factor, like poor governance or economic instability?

#### Causal Inference

**Causal inference** takes things a step further and asks deeper questions:

- What would have happened if something had been different?

- Would a country have avoided a financial crisis if it had implemented stricter banking regulations?

- Would voter turnout have increased if election day had been declared a national holiday?

It’s not enough to observe patterns—we want to understand **the cause** behind those patterns.

For example, it’s descriptive to say that countries with strong EMB capacity tend to experience fewer civil wars. But it’s causal to ask: Does strengthening EMB capacity reduce the likelihood of civil war? That’s the heart of causal inference—trying to isolate the effect of one factor on another, while ruling out other possible explanations.

Here, the researcher is not only describing what is happening, but also trying to estimate what would happen if we changed something—what happens to Y when we change X.

In short, descriptive inference tells us what is happening, while causal inference helps us understand why it’s happening—and what might happen if we intervene or make a change. That shift—from observing the world to imagining how it might change—is what makes causal inference such a powerful tool in political science and beyond.

### Counterfactual Conditions

Causal inference is all about asking, “What would have happened if things had been different?” This is what we call a **counterfactual question**.

For example, imagine a country that experienced a civil war and scored low on Election Management Body (EMB) capacity. Now we might wonder: Would this country have had a higher EMB capacity if it hadn’t gone through a civil war? That’s a causal question. But here’s the challenge: we only ever see what actually happened—not what could have happened under a different scenario. We don’t get to observe both versions of the world for the same country.

This gap is known as **the fundamental problem of causal inference.** For every country, we only observe one outcome: either it had a civil war or it didn’t. But to understand causality, we need to compare what did happen to what would have happened. Since we can’t directly observe the counterfactual, we need to estimate it using data from other, similar units—and this is where good research design comes in.

### Realized Causal Effects

A realized causal effect is the difference between two outcomes: one that we observed, and one that we didn’t but wish we could have.

For unit $i$, the realized causla effect is 

$$
y_i^I - y_i^N
$$

Where $y_i^I$ is the actual observation, and $y_i^N$ is the counterfactual situation.

Let’s take our earlier example. Suppose Country A experienced civil war in the year 1990 and scored 1.2 on EMB capacity. What would its score have been if it hadn’t had a civil war? Maybe it would have been 2.0. The realized causal effect would then be:

$$
\text{Causal Effect} = 1.2 \text{(actual)} - 2.0 \text{(counterfactual)} = -0.8
$$

But remember — we don’t actually get to observe that counterfactual 2.0. We have to estimate it, perhaps by looking at countries similar to Country A that didn't experience civil war. This is the fundamental problem of causal inference. No matter how perfect the research design, no matter how much data we collect, no matter how perceptive the observers, and no matter how much experimental control we have, we will never know a causal inference for certain. 

### Random Causal Effects

In social science, it helps to think about the world as made up of both **systematic** and **nonsystematic** parts. To see why this matters, imagine a parallel universe where Country A goes through a civil war in 1990. In that world, the country's EMB ends up with a certain capacity score. Now imagine we could replay that same scenario — same country, same civil war — across many different versions of the universe. Even though the civil war always happens, the EMB capacity score might turn out differently each time. Why? Because of things we can't fully predict or control — like what neighboring countries were doing or if the country’s leader suddenly changed. These kinds of features are what we call nonsystematic features, and they make outcomes vary even when the main treatment stays the same.

These features reflect the randomness not captured by our theoretical model. We can therefore imagine a variable that would express the values of the EMB capacity score across hypothetical replications of this same situation. This variable is called a **"random variable"** since it has nonsystematic features: it is affected by explanatory variables not encompassed in our theoretical analysis or contains fundamentally unexplainable variability. We define the random variable representing the EMB capacity score under civil war as $Y_i^I$ and under peace as $Y_i^N$.

The **random causal effect** would then be : 

$$
Y_i^I - Y_i^N
$$

This variation in outcomes reflects the random causal effect — the difference caused by civil war in a single replication, influenced by unpredictable factors. When we imagine running many versions of Country A with civil war and many versions without civil war, each with slightly different outcomes, what we’re really doing is building up a sense of how the realized causal effect (in one instance) becomes a random causal effect (across many possibilities).

### Mean Causal Effects

The **mean causal effect** takes things a step further. Instead of looking at just one pair of hypothetical outcomes, it asks: *On average, how does civil war affect EMB capacity?*

We again define:

- $Y_i^I$: the EMB capacity score for country $i$ **if** civil war occurs  

- $Y_i^N$: the EMB capacity score for country $i$ **if** civil war does not occur

Then the **mean causal effect** for unit $i$ is the expected value (the average EMB capacity score across these replications) of the random causal effect:

$$
\text{Mean Causal Effect}_i = E(Y_i^I - Y_i^N)
$$



## Part 2: Definitions of Causality

### Causal Mechanisms

A causal mechanism refers to the process through which a cause produces an effect. It represents the sequence of events or interactions that connect the explanatory variable (cause) to the outcome (effect). Identifying mechanisms helps researchers explain how or why a causal relationship exists, providing theoretical depth and empirical clarity.

For instance, suppose a study finds that countries with strong Election Management Bodies (EMBs) tend to have fewer civil wars. A possible causal mechanism might be that strong EMBs increase public trust in electoral processes, reduce political grievances, and thereby decrease the likelihood of conflict. Here, trust-building is one step in the causal mechanism linking EMB capacity to peace.

While causal mechanisms are incredibly valuable for theory development and qualitative analysis (such as through process tracing or case studies), they do not replace the need for a precise definition of causality. According to King, Keohane, and Verba (1994), identifying causal mechanisms requires prior causal inference for each step in the chain. Moreover, because an infinite number of steps could lie between a cause and an effect, relying solely on mechanisms without a foundational causal framework can lead to infinite regress.

In short, while mechanisms help illustrate and support a causal story, they are not themselves a definition of causality. The core remains a counterfactual comparison between what happened and what would have happened under a different condition.

### Multiple Causation

Multiple causation refers to situations where more than one factor contributes to the occurrence of an outcome. This concept is common in social science, where outcomes are rarely the result of a single cause. For example, the outbreak of civil war in a country might depend on a combination of low economic development, ethnic fragmentation, and weak state capacity.

This idea aligns with the concept of "equifinality"—different combinations of causes can produce the same result. In quantitative research, this can be modeled using interaction terms or by comparing multiple categories of causal variables. In qualitative research, scholars like Charles Ragin advocate for case-oriented approaches that can accommodate such complexity.

Multiple causation doesn't undermine the counterfactual definition of causality. Instead, it emphasizes the importance of clearly specifying the different conditions being compared. For example, comparing someone with a college degree and no job experience to someone without a degree but with four years of experience is a specific counterfactual pair. Different pairings might lead to different causal effects.

Thus, the principle of multiple causation reinforces the need for precise counterfactual thinking. The existence of many contributing factors does not alter the basic logic of causal inference—it just increases the complexity of defining and estimating the effect of each factor.

### Symmetric and Asymmetric Causality

Symmetric causality assumes that the effect of increasing a causal variable is equal in magnitude but opposite in direction to the effect of decreasing it. Asymmetric causality, by contrast, occurs when the impact of increasing a variable differs from the impact of decreasing it.

Consider the case of political incumbency. Suppose a candidate gains a vote share boost by becoming the incumbent. Symmetric causality would imply that losing incumbency results in an equal drop in vote share. But if incumbency helps a party build long-term organizational strength, losing the incumbent might not reverse those gains—this would be an example of asymmetric causality.

According to King, Keohane, and Verba, these distinctions are relevant when interpreting causal inferences, but they do not redefine what causality means. They reflect specific features of empirical relationships, not the fundamental concept of a causal effect, which remains a comparison between two potential outcomes.

In sum, symmetric and asymmetric effects describe how a causal relationship operates in specific cases, but they don’t change the basic definition of causality based on counterfactual reasoning.

## Part 3: Assumptions Required for Estimating Causal Effects

To draw valid causal inferences, we need to make a few critical assumptions. These are often invisible but essential.

Unit Homogeneity

This assumption says that units respond similarly to the treatment. In other words, the causal effect is the same across all cases—or at least similar enough to be estimated on average.

If countries respond very differently to the same institutional reform, the average effect may not tell us much.

Conditional Independence (a.k.a. No Confounding)

Also known as ignorability, this assumption means that, after we account for relevant background variables, the treatment is as good as randomly assigned.

This is often the most difficult assumption to justify in observational studies, but it’s essential: without it, we can’t isolate the effect of X on Y.

## Part 4: Rules for Constructing Causal Theories

Now that we know what causality means and what assumptions are needed, how do we build strong causal theories?

1. Construct Falsifiable Theories

A theory should make testable predictions. If no evidence could ever contradict it, it’s not scientific.

2. Build Theories That Are Internally Consistent

Avoid contradictions. All parts of your theory should work together logically and clearly.

3. Select Dependent Variables Carefully

Your outcome (dependent variable) should match the question you're asking and be measurable in a meaningful way.

4. Maximize Concreteness

Use concepts that are as specific and measurable as possible. Avoid vague or overly abstract terms.

5. State Theories in as Encompassing Ways as Feasible

Whenever possible, formulate your theory to apply to a broad class of cases—not just a single country, time period, or event.

## Wrapping Up: What We’ve Learned

In this module, we learned that causal inference is all about comparison—between what actually happened and what could have happened under different circumstances. We discussed how to define causality using counterfactuals, explored the role of causal mechanisms and multiple causes, and laid out the key assumptions needed to estimate causal effects reliably. We also covered the essential elements for constructing strong causal theories: clarity, concreteness, internal consistency, and falsifiability.

Now that you’ve completed Modules 1 through 3, it’s time to check your understanding.
Next up: a quiz and Problem Set 1, where you’ll apply what you've learned so far. Make sure to complete these before moving on to the next module!

