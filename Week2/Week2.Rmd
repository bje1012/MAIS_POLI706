---
title: "Review of Basics"
output:
  html_document:
    theme: cerulean
    highlight: kate
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: false
---

```{=html}
<style>
body {
  font-size: 17px;
  line-height: 1.6;
}
</style>
```

```{r setup, include=FALSE}
library(kernlab)
library(showtext)
library(kableExtra)
library(dplyr)
library(tidyverse)
library(scales)
```

## Revisiting the Basics – Descriptive and Bivariate Statistics

Before we dive deeper into modeling techniques, it's important to make sure we're all on the same page with the foundational tools you should have mastered in POLI 502 (or a similar introductory methodology course). In the first part of this module, we'll review univariate statistics—such as distributions, measures of central tendency, variance, and standard deviation. Then, in the second part, we’ll move on to bivariate statistics, including covariance, correlation, and t-tests. These are core statistical ideas that form the bedrock of all quantitative research, and we’ll be relying on them throughout the rest of the semester. Even if they feel familiar, a clear refresher will help solidify your understanding—and might even add some clarity or depth you didn’t quite get the first time around!

## Part 1: Understanding Univariate Statistics

Before we start exploring relationships between variables, we need to understand how each variable behaves on its own. This is where univariate statistics come in. “Uni” means one—so univariate statistics are all about analyzing a single variable at a time. Whether it’s income, education level, or approval rating, we want to understand what that variable looks like: what’s typical, how much it varies, and how its values are distributed. Let’s walk through the key concepts you'll need to remember.

### What Is a Distribution?

When we talk about a distribution, we're really asking: how are the values of a variable spread out across all of our observations? Think of a distribution as a snapshot of your data. It tells you things like—are most people in your dataset around the same age? Are democracy scores in your sample mostly low, or do they vary widely? Is there an outlier like a country with an unusually high value?

Understanding the distribution of a variable helps you spot important features in your data, such as whether it's skewed to one side, whether the values are clustered or dispersed, and whether any values stand out as unusual. These insights form the foundation of good statistical analysis.

Now, depending on what kind of variable you're working with—categorical or numeric—you’ll want to visualize distributions in different ways.

For numeric or continuous variables, like income or a democracy score, **histograms** are your go-to tool. A histogram groups the data into ranges (called bins) and shows how many observations fall into each. It’s great for spotting patterns like skewness (is the data lopsided?), peaks (where most values fall), and gaps. Unlike bar charts, the bars in a histogram touch each other, reflecting the continuous nature of the variable.

```{r, echo=FALSE, fig.cap= "Example Histogram", fig.align='center'}
vdem <- read.csv("vdem.csv") %>% drop_na()
vdem %>%
  ggplot(aes(x = v2elembaut)) +
  geom_histogram(fill = "#275D8E", binwidth = 0.2) +
  labs(x = "EMB Autonomy", y = "Count", title = "") +
  theme_bw()
```

For categorical variables—such as region, regime type, or political party—**bar charts** are a better fit. These display each category as a separate bar, with the height of the bar showing how often that category occurs. Since these categories don’t have a natural numerical order, the bars don’t touch. This type of chart makes it easy to compare how frequent each category is.

```{r, echo=FALSE, fig.cap= "Example Bar chart", fig.align='center'}
vdem %>% 
  mutate(region = case_when(e_regionpol_6C == 1 ~ "E. Europe and Central Asia",
                            e_regionpol_6C == 2 ~ "Latin America and the Caribbean",
                            e_regionpol_6C == 3 ~ "The Middle East and N. Africa",
                            e_regionpol_6C == 4 ~ "Sub-Saharan Africa",
                            e_regionpol_6C == 5 ~ "W. Europe and N. America",
                            e_regionpol_6C == 6 ~ "Asia Pacific",
                            )) %>%
# Bar chart for nominal variable
ggplot(aes(x = region)) +
  geom_bar(fill = "#275D8E") +
  labs(title = "", x = "\nRegion", y = "Frequency\n") +
  scale_x_discrete(labels = label_wrap(10)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(hjust = 0.5, size = 8))
```

And then there are **box plots**, which are particularly helpful for comparing numeric variables across groups. A box plot gives you a compact summary of the distribution: it shows the median (the middle value), the range of the middle 50% of the data (called the interquartile range), and any potential outliers. For example, if we wanted to compare EMB capacity scores between countries with and without civil war, a box plot would quickly show us how those distributions differ—and whether one group tends to have higher or more variable values than the other.

```{r, echo=FALSE, fig.cap= "Example box plot", fig.align='center'}
vdem %>%
  group_by(e_civil_war) %>%
  ggplot(aes(x = factor(e_civil_war), y = v2elembcap)) +
  geom_boxplot() +
  labs(x = "Civil War", y = "EMB Capacity", title = "") +
  theme_bw()
```


Finally, if you're interested in how two numeric variables relate to one another, **scatter plots** are the best choice. Each dot represents an observation, plotted according to its values on two axes. If the dots cluster along a line going upward, it suggests a positive relationship—when one variable increases, so does the other. If they form a downward line, the relationship is negative. And if they’re scattered all over, there may be no clear connection. For instance, a scatter plot of EMB autonomy versus EMB capacity could help us visualize whether countries with higher administrative independence also tend to have stronger electoral institutions.

```{r, echo=FALSE, fig.cap= "Example scatter plot", fig.align='center'}
vdem %>%
  ggplot(aes(x = v2elembcap, y = v2elembaut)) +
  geom_point(alpha = 0.1) +
  labs(x = "\nEMB capacity", y = "EMB autonomy\n") + 
  theme_bw()
```


In short, exploring distributions is one of the most important steps in understanding your data. Whether you're using a histogram to see how democracy scores vary across countries, a bar chart to count political regions, or a box plot to compare institutional strength across conflict settings, these visual tools help reveal patterns that numbers alone can’t always show. And the more clearly you can see your data, the better your analysis will be.

### Types of Variables

As I mentioned above, different types of variables require different kinds of summaries and visualizations. Knowing what type of variable you're working with helps you choose the right statistical tools. Here's a quick refresher:

- **Binary Variables**: These variables have only two possible values, typically coded as 0 and 1 (e.g., yes/no, success/failure, male/female).

- **Nominal Variables**: These are categorical variables with no inherent order (e.g., country, religion, party ID).

- **Ordinal Variables**: These have a natural order, but the differences between categories are not necessarily equal (e.g., survey responses like "strongly disagree" to "strongly agree"). 

- **Interval Variables**: Also called continuous variables, these have meaningful numerical values and equal intervals between values (e.g., age, income, temperature).

Here, I will show the examples of each type of data with the sample V-Dem dataset. You can find the dataset file and the codebook on Blackboard.

```{r, results='hide', echo=TRUE, message=FALSE, warning=FALSE}
# Load packages
library(dplyr)
library(tidyverse)
```

```{r}
# Load data (without NA values)
vdem <- read.csv("vdem.csv") %>% drop_na()
```

#### **Binary variable**

```{r}
unique(vdem$e_civil_war)
```

`e_civil_war` is a binary variable which indicates there was an ongoing civil war (1) or not (0).

#### **Nominal Variable**

```{r}
unique(vdem$e_regionpol_6C)
```

The variable `e_regionpol_6C` codes the political region to which a country belongs. The values correspond to the following regions:

1 = Eastern Europe and Central Asia

2 = Latin America and the Caribbean

3 = The Middle East and North Africa

4 = Sub-Saharan Africa

5 = Western Europe and North America

6 = Asia Pacific

Each of these values is simply a label for a region—1 is not “less than” 2, and 6 is not “greater than” 5. They represent distinct categories without any inherent order. That’s what makes this a nominal variable.

#### **Ordinal Variable**

```{r}
sort(unique(vdem$v2elembaut_ord))
```

`v2elembaut_ord` captures how independently the Election Management Body functions when applying election laws and rules. The variable is ordinal—the numbers represent categories that follow a meaningful order, even if the intervals between them aren't necessarily equal.

#### **Interval Variable**

```{r}
head(vdem$v2x_polyarchy, 10)
```

`v2x_polyarchy` represents Electoral Democracy Index. Because the values fall along a continuous scale and can take on many decimal points, `v2x_polyarchy` is a interval variable.

### Measures of Central Tendency

This is about figuring out the “middle” or “typical” value in a variable:

- **Mean**: This is the average—the sum of all values divided by the number of values. It’s great when your data are symmetrical but can be thrown off by outliers (e.g., one billionaire in a dataset about income).

- **Median**: The middle value when data are ordered. It’s more robust to extreme values and a better summary when the distribution is skewed.

- **Mode**: The most common value. This is especially useful for categorical variables.

#### **For binary varable**:

```{r, fig.align='center', fig.width= 6}
vdem %>%
  ggplot(aes(x = factor(e_civil_war))) +
  geom_bar(fill = "#275D8E") +
  labs(title = "Binary Variable\n", x = "Civil War", y = "Frequency\n") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

**Mean (Proportion)**:

When a binary variable is coded as 0 or 1, the mean is equal to the proportion of 1's in the data. For example, for the civil war variable, the mean is:

```{r}
mean(vdem$e_civil_war)
```

This means that approximately 5.04% of the observations experienced a civil war (coded as 1), while the remaining 94.96% did not (coded as 0).

**Mode**:

The mode is the value that occurs most frequently in the data. For a binary variable, which only takes on values 0 or 1, the mode will be either 0 or 1, depending on which one appears more often.
In the case of the civil war variable, the mode is 0,  meaning that more observations in the dataset represent countries not experiencing civil war.

#### **For nominal variable**:

```{r, fig.align='center', message=FALSE}
# For more organized labels 
library(scales)

# Change the numbers into the names of regions
vdem %>% 
  mutate(region = case_when(e_regionpol_6C == 1 ~ "E. Europe and Central Asia",
                            e_regionpol_6C == 2 ~ "Latin America and the Caribbean",
                            e_regionpol_6C == 3 ~ "The Middle East and N. Africa",
                            e_regionpol_6C == 4 ~ "Sub-Saharan Africa",
                            e_regionpol_6C == 5 ~ "W. Europe and N. America",
                            e_regionpol_6C == 6 ~ "Asia Pacific",
                            )) %>%
# Bar chart for nominal variable
ggplot(aes(x = region)) +
  geom_bar(fill = "#275D8E") +
  labs(title = "Nominal Variable\n", x = "\nRegion", y = "Frequency\n") +
  scale_x_discrete(labels = label_wrap(10)) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5),
        axis.text.x = element_text(hjust = 0.5, size = 8))
```

The **mode** is often the most meaningful measure of central tendency for nominal variables, since it tells us which category appears most frequently. In our sample dataset, Latin America and the Caribbean is the mode of the e_regionpol_6C variable, meaning it is the most common region represented in the data. This makes sense for nominal variables, where we cannot compute a meaningful average or median, but we can still identify the most frequently occurring category.

#### **For ordinal variable**:

```{r, fig.align='center'}
# Find the median value
med_val <- median(vdem$v2elembaut_ord)

# Plot the variable
vdem %>%
  mutate(v2elembaut_ord = factor(v2elembaut_ord),
         is_median = ifelse(v2elembaut_ord == as.character(med_val), "Median", "Other")) %>%
  ggplot(aes(x = v2elembaut_ord, fill = is_median)) +
  geom_bar() +
  scale_fill_manual(values = c("Median" = "#E69F00", "Other" = "#275D8E")) +
  labs(title = "Ordinal Variable\n", x = "\nEMB Autonomy", y = "Frequency\n", fill = NULL) +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5))
```

For ordinal data, the most appropriate measure of central tendency is the median. The median represents the middle value when the data is ordered, and it is not affected by extreme values or outliers, which can skew the mean. While the mode can also be used, the median provides a more informative summary of the center of the ordinal data.

In our sample data, the median value is:

```{r}
median(vdem$v2elembaut_ord)
```

This means that 1 is the middle category of the v2elembaut_ord variable—indicating that, when all values are ordered, half of the observations fall below this category and half fall above it. 

#### **For interval variable**:

```{r, fig.align='center'}
p1 <- vdem %>%
  ggplot(aes(x = v2x_polyarchy)) +
  geom_histogram(color = "white", fill = "gray", bins = 25) +
  geom_vline(aes(xintercept = mean(v2x_polyarchy, na.rm = TRUE), 
                 color = "mean"), linetype = "dashed") +
  geom_vline(aes(xintercept = median(v2x_polyarchy, na.rm = TRUE), 
                 color = "median"), linetype = "dashed") +
  labs(title = "Interval Variable\n", x = "", y = "Frequency\n") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5)) + 
  scale_color_manual(name = "", values = c(median = "#E69F00", mean = "#275D8E"))

p2 <- vdem %>%
  ggplot(aes(x="", y = v2x_polyarchy)) +
  geom_boxplot(fill = "gray", color = "black") + 
  coord_flip() +
  labs(x = "", y = "\nElectoral Democracy Index") +
  theme_bw() +
  theme(axis.text.y=element_blank(),
        axis.ticks.y=element_blank())

library(patchwork)
p1 + p2 + plot_layout(nrow = 2, heights = c(2, 1))
```

In the case of interval variable, both the mean and the median are commonly used to describe the central tendency of the data. But which one is more appropriate depends on the shape of the distribution and whether there are outliers.

The **mean** is the arithmetic average—add up all the values and divide by the number of observations. It uses all the values in the dataset, which makes it sensitive to extreme values (outliers). When the data is symmetrically distributed, the mean gives a very good summary of the "center" of the data. In contrast, the **median** is less affected by outliers or skewed distributions, so it's a better choice when the data is not symmetrical or contains a few extreme values.

In our sample data, the mean and median values are:

```{r}
mean(vdem$v2x_polyarchy)
median(vdem$v2x_polyarchy)
```

The fact that the mean is higher than the median suggests that the distribution of v2x_polyarchy is right-skewed. In other words, a few countries with very high democracy scores are pulling the average up, even though the majority of countries score lower. In such cases, the median may provide a better sense of what is "typical" or common among countries, while the mean can be useful for understanding the overall level across the dataset.

### Variance and Standard Deviation (SD)

So far, we’ve talked about the mean, median, and mode as ways to describe the “center” of a distribution. But what about the spread—how far values are from the center? That’s where variance and standard deviation (SD) come in. These two measures help us understand how dispersed the values are in a dataset.

Variance is calculated by taking the difference between each value and the mean, squaring those differences, and then averaging the squared differences. This gives us a sense of how “spread out” the data is, though the result is in squared units—which can make it harder to interpret directly.

$$
\text{Variance} = s^2 = \frac{1}{n - 1} \sum_{i=1}^{n} (x_i - \bar{x})^2
$$

where 

- $x_i$ is the $i$-th observation,  

- $\bar{x}$ is the mean of all observations,  

- $n$ is the number of observations.

The standard deviation is simply the square root of the variance. 

$$
\text{Standard Deviation} = s = \sqrt{s^2}
$$

Because it’s in the same units as the original data, it’s easier to interpret. If the SD is small, the values are clustered close to the mean. If it's large, the values are more spread out. 

```{r}
sd(vdem$v2x_polyarchy)
```

The mean of v2x_polyarchy is 0.39 and the standard deviation is 0.25. If the distribution were normal, we might expect about 68% of countries to fall within one standard deviation of the mean—that is, between 0.14 and 0.64.

```{r, fig.align='center', warning=FALSE}
# Calculate mean and SD
mean_val <- mean(vdem$v2x_polyarchy, na.rm = TRUE)
median_val <- median(vdem$v2x_polyarchy, na.rm =TRUE)
sd_val <- sd(vdem$v2x_polyarchy, na.rm = TRUE)

# Plot
vdem %>%
  ggplot(aes(x = v2x_polyarchy)) +
  geom_histogram(aes(y = ..density..),color = "white", fill = "gray", bins = 25) +
  geom_vline(aes(xintercept = mean_val, color = "mean"), linetype = "dashed") +
  geom_vline(aes(xintercept = median_val, color = "median"), linetype = "dashed") +
  # Normal distribution line
  stat_function(fun = dnorm, args = list(mean = 0.39, sd = 0.25), 
                color = "red", size = 0.7) +
  # Shaded area for ±1 SD
  annotate("rect",
           xmin = max(0, mean_val - sd_val), 
           xmax = min(1, mean_val + sd_val),
           ymin = 0,
           ymax = Inf,
           alpha = 0.2,
           fill = "lightgreen") +
  labs(title = "Electoral Democracy Index\n", x = "\nElectoral Democracy Index",
       y = "Density\n") +
  theme_bw() +
  theme(plot.title = element_text(hjust = 0.5), 
        plot.subtitle = element_text(hjust = 0.5)) +
  scale_color_manual(name = "", values = c(median = "#E69F00", mean = "#275D8E"))
```

However, because the distribution is not normal, the usual rule of thumb—that 68% of values fall within one standard deviation of the mean—doesn’t quite apply here. That’s why it’s helpful to look at the actual histogram to get a clearer sense of how the scores are spread out.

In the plot below, we visualize how electoral democracy index are distributed across countries. Each gray bar represents how many countries fall within a specific range of scores. This gives us a sense of where the data are concentrated. We also added a red dashed curve, which shows what the distribution would look like if it followed a perfect normal (bell-shaped) distribution, based on a mean of 0.39 and a standard deviation of 0.25. This curve helps us visually compare the actual data to the theoretical expectation.

Two vertical dashed lines indicate the actual center points of the data: the blue line shows the mean score, while the orange line shows the median. In a symmetric, normal distribution, these would be close together—but here, the mean is to the right of the median, suggesting that the data are right-skewed—with a long tail of higher democracy scores pulling the mean upward.

Finally, the light green shaded region shows the range within one standard deviation (±1 SD) of the mean—approximately from 0.14 to 0.64. This is often considered a “typical range,” but only when the distribution is normal. Since our data are skewed, this range doesn't capture the full picture. This is why it’s so important to examine the shape of the distribution—not just the summary statistics—when interpreting data like this.

## Part 2: Understanding Bivariate Statistics

Once we’ve developed a clear understanding of individual variables—such as how they’re distributed, their central tendencies, and how spread out their values are—the next logical step is to explore how two variables relate to each other. This brings us into the realm of bivariate statistics.

Bivariate analysis allows us to investigate whether and how variables move together. For example, do countries with higher levels of education also tend to have higher levels of democracy? Does income vary significantly between those who live in urban areas versus rural ones? These kinds of questions require tools that help us quantify and assess relationships between pairs of variables.

In this section, we’ll review three key concepts used in bivariate analysis:

- Covariance, which tells us whether two variables tend to increase or decrease together (but not how strong or meaningful the relationship is),

- Correlation, which standardizes this relationship to a scale from -1 to 1 so we can better understand the strength and direction of the association

- t-tests, which help us determine whether the difference in means between two groups is statistically significant or could have happened by chance.

Together, these tools will allow us to move beyond describing variables in isolation and start making informed comparisons and evaluating possible connections between them.

### Covariance and Correlation

#### **Covariance**

Covariance helps us understand how two variables move together:

- A positive covariance suggests that as one variable increases, the other tends to increase too.

- A negative covariance means that as one variable increases, the other tends to decrease.

- A covariance close to zero indicates no clear pattern of association.


```{r, include=FALSE}
jointtable <- table(vdem$v2elembcap_ord, vdem$v2elembaut_ord)

joint_percent <- prop.table(jointtable) 

joint_table <- addmargins(joint_percent, FUN = list(Total = sum))
```


```{r, echo=FALSE}
kable(joint_table, digits = 3, caption = "Joint Distribution of EMB Capacity and EMB Autonomy",
      col.names = c("EMB capacity", "0", "1", "2", "3", "4", "Total")) %>%
  add_header_above(c(" " = 1, "EMB autonomy" = 5, " " = 1)) %>%
  kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover"))
```

In our dataset:

- `v2elembcap_ord` (EMB capacity) is an ordinal variable, ranging from 0 (no capacity) to 4 (full capacity).

- `v2elembaut_ord` (EMB autonomy) is also an ordinal variable, ranging from 0 (no autonomy) to 4 (full autonomy).

Now look at the joint percentage table above. We can spot a clear pattern:

Countries with low EMB capacity (row 0 and 1) tend to cluster in the lower autonomy columns (column 0 and 1). For instance, countries with EMB capacity 0 have 14.3% of cases in autonomy level 0 and 4.0% in level 1.

On the other hand, countries with high EMB capacity (row 4) have more representation in the higher autonomy levels. For example, at capacity level 4, 13.5% of observations fall in autonomy level 4, and 7.5% in level 3.

This indicates a positive relationship—as EMB capacity increases, EMB autonomy tends to increase as well.

#### **Then How is Covariance Calculated?**

The formula for calculating the covariance between two variables $X$ and $Y$ is:

$$
\text{Cov}(X, Y) = \mathbb{E}[(X - \mu_X)(Y - \mu_Y)] = \mathbb{E}(XY) - \mathbb{E}(X)\mathbb{E}(Y)
$$

Here:

- $\mathbb{E}$ stands for the expected value (or average),
- $\mu_X4$ and $\mu_Y$ are the means of variables $X$ and $Y4, respectively.

This equation shows that covariance is essentially the average product of how far each observation is from the mean of its variable. 

If $X$ and $Y$ tend to be above (or below) their means at the same time, the product is positive—leading to a **positive covariance**. If one tends to be above while the other is below, the product is negative—resulting in a **negative covariance**.

Let's apply this to our dataset.

In our case, we are interested in understanding the relationship between **EMB capacity** (Election Management Body Capacity) and **EMB aut** (Election Management Body Autonomy).

We can think of these variables as $X = \text{EMB capacity}$ and $Y = \text{EMB autonomy}$. To compute the covariance between these two variables, we follow these steps:

The mean of $X$:  

```{r}
meanX <- mean(vdem$v2elembcap_ord)
meanX
```


The mean of $Y$:  

```{r}
meanY <- mean(vdem$v2elembaut_ord)
meanY
```

For each country, calculate $(X_i - \mu_X)(Y_i - \mu_Y)$, and then take the average across all observations:

$$
\text{Cov}(X, Y) = \frac{1}{n-1} \sum_{i=1}^{n} (X_i - \mu_X)(Y_i - \mu_Y)
$$

```{r}
sum((vdem$v2elembcap_ord - meanX) * (vdem$v2elembaut_ord - meanY)) / (nrow(vdem) - 1)
```

We can also use R’s built-in `cov()` function:

```{r}
cov(vdem$v2elembcap_ord, vdem$v2elembaut_ord)
```

Both methods give the same result.

This positive covariance suggests that countries with higher EMB capacity also tend to have higher EMB autonomy. However, to better understand the strength and scale-free direction of this relationship, we’ll next turn to correlation.

#### **Correlation**

While covariance tells us the direction of the relationship between two variables, it doesn’t tell us how strong the relationship is—nor is it easy to interpret because the result depends on the units of the original variables.

That’s where correlation comes in. The correlation coefficient is a standardized measure of the strength and direction of a linear relationship between two variables. It ranges from:

- +1: a perfect positive linear relationship

- 0: no linear relationship

- –1: a perfect negative linear relationship

The formula for correlation is:

$$
\text{Cor}(X, Y) = \frac{\text{Cov}(X, Y)}{\sigma_X \cdot \sigma_Y}
$$
Where:

- $\text{Cor}(X, Y)$ is the covariance,

- $\sigma_X$ is the standard deviation of X,

- $\sigma_Y$ is the standard deviation of Y,

This formula essentially scales the covariance by the variability of each variable, which makes the result unit-free and thus easier to interpret.

Let’s calculate the correlation between EMB capacity and EMB autonomy:

```{r}
cov(vdem$v2elembcap_ord, vdem$v2elembaut_ord) / (sd(vdem$v2elembcap_ord) * sd(vdem$v2elembaut_ord))
```

Using R function `cor()`:

```{r}
cor(vdem$v2elembcap_ord, vdem$v2elembaut_ord)
```

The value 0.6859 is positive. This result tells us that there’s a positive linear relationship between EMB capacity and EMB autonomy. In general, countries with higher EMB capacity also tend to have higher EMB autonomy, and vice versa.

### T-tests

A t-test is a statistical tool used to compare the means of two groups and assess whether the observed difference between them is statistically significant—that is, unlikely to have occurred by chance alone.

For example, imagine we want to know whether countries experiencing civil war differ from those that don’t in terms of the capacity of their Election Management Body (EMB). We might expect that civil conflict would weaken institutions, and a t-test allows us to test that expectation.

Let’s set it up:

Group 1: Countries not in civil war (`e_civil_war` == 0)

Group 2: Countries in civil war (`e_civil_war` == 1)

Variable of interest: `v2elembcap` EMB capacity (Interval variable)

We want to know:

Do countries with civil war have lower average EMB capacity than those without?

To better understand the relationship between EMB capacity and the presence of civil war, we first looked at a summary table showing the average EMB capacity for each group—countries with and without civil conflict.

According to the table:

```{r}
vdem %>% 
  group_by(e_civil_war) %>%
  summarize(mean_cap = mean(v2elembcap), n = n()) %>%
  kable(col.names = c("Civil War", "Mean (EMB capacity)", "Number of Observation")) %>%
  kable_styling(full_width = TRUE, bootstrap_options = c("striped", "hover"))
```

This tells us that, on average, countries without a civil war have a higher EMB capacity score (0.25), while countries with a civil war have a much lower average score (–0.71). The large difference in these mean values already suggests a strong link between civil conflict and weaker electoral institutions.

To visualize this relationship, we also created a boxplot. In this plot, the x-axis separates the two groups (civil war = 0 and 1), and the y-axis shows the distribution of EMB capacity scores within each group.

```{r, fig.align='center', fig.cap= "Average EMB Capacity by Civil War Status"}
vdem %>%
  group_by(e_civil_war) %>%
  ggplot(aes(x = factor(e_civil_war), y = v2elembcap)) +
  geom_boxplot() +
  labs(x = "Civil War", y = "EMB Capacity", title = "") +
  theme_minimal()
```

The boxplot reinforces what we saw in the summary table: countries without civil war tend to have EMB capacity scores clustered around higher values. In contrast, countries experiencing civil war not only have lower average scores but also show less variation, with most values packed around those low numbers. You can clearly see from the boxplot that the median is lower for civil war countries, and the overall distribution is shifted downward.

But while visualizations and mean comparisons give us a good starting point, they don’t tell us whether the differences we see are statistically significant—that is, whether the difference is likely to be real or just due to random variation in our sample. That’s where the t-test comes in.

Now, we conduct a t-test to formally compare the two group means and determine whether the difference in EMB capacity between civil war and non-civil war countries is statistically meaningful.

```{r}
t.test(v2elembcap ~ e_civil_war, data = vdem)
```

The results of the t-test show a clear and meaningful difference in EMB (Election Management Body) capacity between countries with and without civil war. The p-value is extremely small—much smaller than the usual cutoff of 0.05—which means we can confidently reject the idea that there’s no difference between the two groups.

Looking at the 95% confidence interval, the difference in average EMB capacity scores is estimated to fall between 0.83 and 1.09 points. In simple terms, countries without civil war tend to score much higher on EMB capacity than those that are currently experiencing conflict.

Here’s what the group averages look like:

- No civil war: average EMB capacity = 0.25

- Civil war: average EMB capacity = –0.71

That’s a big gap! This result suggests that countries not in conflict tend to have stronger electoral institutions. Of course, we can’t say from this test alone whether strong EMBs help prevent conflict or whether conflict weakens them—but either way, there’s a strong relationship worth paying attention to.

## Wrapping Up: What We’ve Learned

In this module, we explored how to summarize and visualize data to better understand patterns, relationships, and differences across groups. We began by discussing distributions—how data values are spread—and the importance of choosing the right visualization based on whether a variable is numeric or categorical.

We also learned how to measure relationships numerically. We calculated covariance to understand whether two variables move together, and used correlation to measure the strength and direction of that movement on a standardized scale. Finally, we ran a t-test to see whether the difference in a variable between different groups is statistically significant or if the difference might just be due to random chance.

As you move forward, keep in mind that descriptive statistics and data visualization aren’t just academic exercises—they’re tools to help you tell stories with data. Whether you're exploring institutional strength, conflict, democracy, or any other topic, these techniques lay the groundwork for deeper analysis and stronger arguments.

In the next module, we’ll begin moving toward the concept of causal inference and how it connects to statistical models. But first, make sure you're comfortable with everything in this module.


